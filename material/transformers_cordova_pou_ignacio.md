---
output:
  pdf_document: default
  html_document: default
---
# 1. Transformers 
by Ignacio Cordova Pou

Veo que lo voy a hacer primero a mano y luego ya lo pasar√© a markdown.

1. Introduction
2. Key must know concepts 
    
    2.1. Encoder-Decoder Architecture
    
    2.2. Recurrent Neural Networks
    
    2.3. Long Short-Term Memory (LSTM)
    
    2.4. Sequence to sequence information flow 

3. Attention Mechanism 
    
    3.1. Query, Key, Value (Q, K, V)

    3.2. Seq2seq + Attention 

4. Transformer Architecture


## Introduction: The Transformer revolution



